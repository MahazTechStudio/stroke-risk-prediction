from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import pandas as pd
import numpy as np
from pydantic import BaseModel
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import xgboost as xgb
from lime import lime_tabular
import uvicorn

app = FastAPI()
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFilesfrom fastapi.staticfiles import StaticFiles
# Mount /static to serve index.html
app.mount("/static", StaticFiles(directory="static", html=True), name="static")

# Serve index.html as root page
@app.get("/")
async def root():
    return FileResponse("static/index.html")
# ✅ CORS Middleware for your frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://enzostvs-deepsite.hf.space"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ✅ Manually handle OPTIONS for /predict to satisfy preflight
@app.options("/predict")
async def preflight(request: Request):
    return JSONResponse(
        content={"message": "Preflight passed"},
        headers={
            "Access-Control-Allow-Origin": "https://enzostvs-deepsite.hf.space",
            "Access-Control-Allow-Methods": "POST, OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type",
        },
        status_code=200,
    )

# ✅ Load Dataset
df = pd.read_csv("full_data.csv")

# ✅ Fill Missing Values
if "bmi" in df.columns:
    df["bmi"].fillna(df["bmi"].median(), inplace=True)
if "smoking_status" in df.columns:
    df["smoking_status"].fillna("Unknown", inplace=True)

# ✅ Encode Categorical
label_encoders = {}
categorical_columns = ["gender", "ever_married", "work_type", "Residence_type", "smoking_status"]
for col in categorical_columns:
    if col in df.columns:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        label_encoders[col] = le

# ✅ Normalize Numeric
scale_columns = ["age", "avg_glucose_level", "bmi"]
scaler = MinMaxScaler()
df[scale_columns] = scaler.fit_transform(df[scale_columns])

# ✅ Define Features & Target
target_column = "stroke"
feature_columns = [col for col in df.columns if col != target_column]
X = df[feature_columns]
y = df[target_column]

# ✅ Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ✅ Train Models
log_model = LogisticRegression(max_iter=1000).fit(X_train, y_train)
xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, seed=42).fit(X_train, y_train)
rf_model = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)

# ✅ Lime Explainer
lime_explainer = lime_tabular.LimeTabularExplainer(
    training_data=np.array(X_train),
    feature_names=X.columns,
    class_names=["No Stroke", "Stroke"],
    mode='classification'
)

# ✅ FastAPI App
app = FastAPI()

class InputData(BaseModel):
    gender: str
    age: float
    hypertension: int
    heart_disease: int
    ever_married: str
    work_type: str
    Residence_type: str
    avg_glucose_level: float
    bmi: float
    smoking_status: str
    model: str = "logreg"  # default

def preprocess_input(data: dict):
    # Encode categorical
    for col in categorical_columns:
        if col in data:
            le = label_encoders[col]
            data[col] = le.transform([data[col]])[0]

    # Convert to DataFrame with correct column order
    df_input = pd.DataFrame([data], columns=feature_columns)

    # Normalize numeric columns (in-place with correct column names)
    df_input[scale_columns] = scaler.transform(df_input[scale_columns])

    return df_input

@app.post("/predict")
def predict_risk(input_data: InputData):
    data_dict = input_data.dict()
    model_type = data_dict.pop("model")

    input_df = preprocess_input(data_dict)

    # Select model
    if model_type == "xgboost":
        model = xgb_model
    elif model_type == "randomforest":
        model = rf_model
    else:
        model = log_model

    # Predict probability
    prob = float(model.predict_proba(input_df)[0][1])  # Ensures JSON-serializable

    # LIME explainability (pass named data)
    exp = lime_explainer.explain_instance(
        data_row=input_df.iloc[0],
        predict_fn=lambda x: model.predict_proba(pd.DataFrame(x, columns=feature_columns))
    )
    explanation = {feature: round(weight, 4) for feature, weight in exp.as_list()}

    return {
        "risk_score": float(round(prob, 4)),
        "model": model_type,
        "lime_explanation": explanation
    }

# ✅ To run:
# uvicorn api_server:app --host 0.0.0.0 --port 8000 --reload
